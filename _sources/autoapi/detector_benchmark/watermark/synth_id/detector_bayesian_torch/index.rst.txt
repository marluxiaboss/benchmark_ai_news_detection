detector_benchmark.watermark.synth_id.detector_bayesian_torch
=============================================================

.. py:module:: detector_benchmark.watermark.synth_id.detector_bayesian_torch


Classes
-------

.. autoapisummary::

   detector_benchmark.watermark.synth_id.detector_bayesian_torch.LikelihoodModel
   detector_benchmark.watermark.synth_id.detector_bayesian_torch.LikelihoodModelWatermarked
   detector_benchmark.watermark.synth_id.detector_bayesian_torch.LikelihoodModelUnwatermarked
   detector_benchmark.watermark.synth_id.detector_bayesian_torch.BayesianDetectorModule
   detector_benchmark.watermark.synth_id.detector_bayesian_torch.RawBayesianDetector


Functions
---------

.. autoapisummary::

   detector_benchmark.watermark.synth_id.detector_bayesian_torch.pad_to_len
   detector_benchmark.watermark.synth_id.detector_bayesian_torch.filter_and_truncate
   detector_benchmark.watermark.synth_id.detector_bayesian_torch.process_outputs_for_training
   detector_benchmark.watermark.synth_id.detector_bayesian_torch.train_model


Module Contents
---------------

.. py:function:: pad_to_len(arr: torch.Tensor, target_len: int, *, left_pad: bool, eos_token: int, device: torch.device) -> torch.Tensor

   Pad or truncate array to given length.


.. py:function:: filter_and_truncate(outputs: torch.Tensor, truncation_length, eos_token_mask: torch.Tensor) -> torch.Tensor

   Filter and truncate outputs to given length.


.. py:function:: process_outputs_for_training(all_outputs: collections.abc.Sequence[torch.Tensor], logits_processor, tokenizer: Any, *, pos_truncation_length, neg_truncation_length, max_length: int, is_cv: bool, is_pos: bool, torch_device: torch.device) -> tuple[collections.abc.Sequence[torch.Tensor], collections.abc.Sequence[torch.Tensor]]

   Process raw model outputs for training.


.. py:class:: LikelihoodModel

   Bases: :py:obj:`torch.nn.Module`, :py:obj:`abc.ABC`


   Base class for likelihood models.


   .. py:method:: forward(g_values: torch.Tensor) -> torch.Tensor
      :abstractmethod:


      Compute likelihoods given g-values.



.. py:class:: LikelihoodModelWatermarked(watermarking_depth: int)

   Bases: :py:obj:`LikelihoodModel`


   Model for P(g_values|watermarked).


   .. py:attribute:: watermarking_depth


   .. py:attribute:: beta


   .. py:attribute:: delta


   .. py:method:: l2_loss() -> torch.Tensor


   .. py:method:: _compute_latents(g_values: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]

      Compute latent probabilities.



   .. py:method:: forward(g_values: torch.Tensor) -> torch.Tensor

      Compute P(g_values|watermarked).



.. py:class:: LikelihoodModelUnwatermarked

   Bases: :py:obj:`LikelihoodModel`


   Model for P(g_values|unwatermarked).


   .. py:method:: forward(g_values: torch.Tensor) -> torch.Tensor

      Compute P(g_values|unwatermarked).



.. py:class:: BayesianDetectorModule(watermarking_depth: int, baserate: float = 0.5)

   Bases: :py:obj:`torch.nn.Module`


   Bayesian detector model.


   .. py:attribute:: watermarking_depth


   .. py:attribute:: baserate


   .. py:attribute:: likelihood_model_watermarked


   .. py:attribute:: likelihood_model_unwatermarked


   .. py:attribute:: prior


   .. py:method:: l2_loss() -> torch.Tensor


   .. py:method:: forward(g_values: torch.Tensor, mask: torch.Tensor) -> torch.Tensor

      Compute P(watermarked|g_values).



.. py:function:: train_model(detector_module: BayesianDetectorModule, g_values: torch.Tensor, mask: torch.Tensor, watermarked: torch.Tensor, epochs: int = 250, learning_rate: float = 0.001, minibatch_size: int = 64, l2_weight: float = 0.0, g_values_val: torch.Tensor = None, mask_val: torch.Tensor = None, watermarked_val: torch.Tensor = None, verbose: bool = False) -> tuple[dict, float]

   Train the detector model.


.. py:class:: RawBayesianDetector(logits_processor, tokenizer: Any, detector_module: BayesianDetectorModule)

   Bayesian detector for watermark detection.


   .. py:attribute:: detector_module


   .. py:attribute:: logits_processor


   .. py:attribute:: tokenizer


   .. py:method:: score(outputs: torch.Tensor) -> torch.Tensor

      Score outputs for watermark detection.



   .. py:method:: train_best_detector(*, tokenized_wm_outputs, tokenized_uwm_outputs, logits_processor, tokenizer: Any, torch_device: torch.device, test_size: float = 0.3, pos_truncation_length: int = 200, neg_truncation_length: int = 100, max_padded_length: int = 2300, n_epochs: int = 50, learning_rate: float = 0.021, l2_weights: numpy.ndarray = np.logspace(-3, -2, num=4), verbose: bool = False) -> tuple[RawBayesianDetector, float]
      :classmethod:


      Train the best detector model.



   .. py:method:: process_raw_model_outputs(*, tokenized_wm_outputs, tokenized_uwm_outputs, logits_processor, tokenizer: Any, torch_device: torch.device, test_size: float = 0.3, pos_truncation_length: int = 200, neg_truncation_length: int = 100, max_padded_length: int = 2300) -> tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray]
      :classmethod:


      Process raw models outputs into inputs for training.

      Args:
          tokenized_wm_outputs: tokenized outputs of watermarked data
          tokenized_uwm_outputs: tokenized outputs of unwatermarked data
          logits_processor: logits processor used for watermarking
          tokenizer: tokenizer used for the model
          torch_device: torch device to use
          test_size: test size for train-test split
          pos_truncation_length: Length to truncate wm outputs
          neg_truncation_length: Length to truncate uwm outputs
          max_padded_length: Length to pad truncated outputs

      Returns:
          Tuple of (train_g_values, train_masks, train_labels,
                   cv_g_values, cv_masks, cv_labels)



