detector_benchmark.watermark.unbiased.unbiased
==============================================

.. py:module:: detector_benchmark.watermark.unbiased.unbiased


Classes
-------

.. autoapisummary::

   detector_benchmark.watermark.unbiased.unbiased.UnbiasedConfig
   detector_benchmark.watermark.unbiased.unbiased.UnbiasedUtils
   detector_benchmark.watermark.unbiased.unbiased.UnbiasedLogitsProcessor
   detector_benchmark.watermark.unbiased.unbiased.UnbiasedWatermark


Module Contents
---------------

.. py:class:: UnbiasedConfig(algorithm_config: dict, gen_model, model_config: detector_benchmark.utils.configs.ModelConfig, *args, **kwargs)

   Config class for Unbiased watermark algorithm, load config file and initialize parameters.


   .. py:attribute:: hash_key


   .. py:attribute:: gamma


   .. py:attribute:: alpha
      :value: 0.5



   .. py:attribute:: ignore_history


   .. py:attribute:: z_threshold


   .. py:attribute:: prefix_length


   .. py:attribute:: generation_model


   .. py:attribute:: generation_tokenizer


   .. py:attribute:: vocab_size


   .. py:attribute:: device


   .. py:attribute:: gen_kwargs


.. py:class:: UnbiasedUtils(config: UnbiasedConfig, *args, **kwargs)

   Utility class for Unbiased watermark algorithm, contains helper functions.


   .. py:attribute:: config


   .. py:attribute:: rng


   .. py:attribute:: cc_history


   .. py:method:: _get_rng_seed(context_code: any) -> int

      Get the random seed from the given context code and private key.



   .. py:method:: _extract_context_code(context: torch.LongTensor) -> bytes

      Extract context code from the given context.



   .. py:method:: from_random(rng: Union[torch.Generator, list[torch.Generator]], vocab_size: int) -> torch.LongTensor

      Generate a permutation from the random number generator.



   .. py:method:: reweight_logits(shuffle: torch.LongTensor, p_logits: torch.FloatTensor) -> torch.FloatTensor

      Reweight the logits using the shuffle and alpha.



   .. py:method:: get_seed_for_cipher(input_ids: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the mask and seeds for the cipher.



   .. py:method:: _get_green_token_quantile(input_ids: torch.LongTensor, vocab_size, current_token)

      Get the vocab quantile of current token



   .. py:method:: _get_score(input_ids: torch.LongTensor, vocab_size)

      Get the score of the input_ids



   .. py:method:: score_sequence(input_ids: torch.LongTensor) -> tuple[float, list[int]]

      Score the input_ids and return z_score and green_token_flags.



.. py:class:: UnbiasedLogitsProcessor(config: UnbiasedConfig, utils: UnbiasedUtils, *args, **kwargs)

   Bases: :py:obj:`transformers.LogitsProcessor`


   LogitsProcessor for DiP algorithm, process logits to add watermark.


   .. py:attribute:: config


   .. py:attribute:: utils


   .. py:method:: _apply_watermark(input_ids: torch.LongTensor, scores: torch.FloatTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Apply watermark to the scores.



   .. py:method:: __call__(input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor

      Process logits to add watermark.



.. py:class:: UnbiasedWatermark(algorithm_config: dict, gen_model, transformers_config: detector_benchmark.utils.configs.ModelConfig, *args, **kwargs)

   Bases: :py:obj:`detector_benchmark.watermark.base.BaseWatermark`


   Top-level class for Unbiased algorithm.


   .. py:attribute:: config


   .. py:attribute:: utils


   .. py:attribute:: logits_processor


   .. py:method:: generate_watermarked_text(prompt: str, *args, **kwargs) -> str

      Generate watermarked text.



   .. py:method:: detect_watermark(text: str, return_dict: bool = True, *args, **kwargs)

      Detect watermark in the text.



