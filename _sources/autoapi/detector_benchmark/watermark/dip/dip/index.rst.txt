detector_benchmark.watermark.dip.dip
====================================

.. py:module:: detector_benchmark.watermark.dip.dip


Classes
-------

.. autoapisummary::

   detector_benchmark.watermark.dip.dip.DIPConfig
   detector_benchmark.watermark.dip.dip.DIPUtils
   detector_benchmark.watermark.dip.dip.DIPLogitsProcessor
   detector_benchmark.watermark.dip.dip.DIP


Module Contents
---------------

.. py:class:: DIPConfig(algorithm_config: dict, gen_model, model_config: utils.configs.ModelConfig, *args, **kwargs)

   Config class for DiP algorithm, load config file and initialize parameters.


   .. py:attribute:: config_dict


   .. py:attribute:: hash_key


   .. py:attribute:: gamma


   .. py:attribute:: alpha


   .. py:attribute:: ignore_history


   .. py:attribute:: z_threshold


   .. py:attribute:: prefix_length


   .. py:attribute:: generation_model


   .. py:attribute:: generation_tokenizer


   .. py:attribute:: vocab_size


   .. py:attribute:: device


   .. py:attribute:: gen_kwargs


.. py:class:: DIPUtils(config: DIPConfig, *args, **kwargs)

   Utility class for DiP algorithm, contains helper functions.


   .. py:attribute:: config


   .. py:attribute:: rng


   .. py:attribute:: cc_history


   .. py:method:: _get_rng_seed(context_code: any) -> int

      Get the random seed from the given context code and private key.



   .. py:method:: _extract_context_code(context: torch.LongTensor) -> bytes

      Extract context code from the given context.



   .. py:method:: from_random(rng: Union[torch.Generator, list[torch.Generator]], vocab_size: int) -> torch.LongTensor

      Generate a permutation from the random number generator.



   .. py:method:: reweight_logits(shuffle: torch.LongTensor, p_logits: torch.FloatTensor) -> torch.FloatTensor

      Reweight the logits using the shuffle and alpha.



   .. py:method:: get_seed_for_cipher(input_ids: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the mask and seeds for the cipher.



   .. py:method:: _get_green_token_quantile(input_ids: torch.LongTensor, vocab_size, current_token)

      Get the vocab quantile of current token



   .. py:method:: _get_dip_score(input_ids: torch.LongTensor, vocab_size)

      Get the DiP score of the input_ids



   .. py:method:: score_sequence(input_ids: torch.LongTensor) -> tuple[float, list[int]]

      Score the input_ids and return z_score and green_token_flags.



.. py:class:: DIPLogitsProcessor(config: DIPConfig, utils: DIPUtils, *args, **kwargs)

   Bases: :py:obj:`transformers.LogitsProcessor`


   LogitsProcessor for DiP algorithm, process logits to add watermark.


   .. py:attribute:: config


   .. py:attribute:: utils


   .. py:method:: _apply_watermark(input_ids: torch.LongTensor, scores: torch.FloatTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Apply watermark to the scores.



   .. py:method:: __call__(input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor

      Process logits to add watermark.



.. py:class:: DIP(algorithm_config: dict, gen_model, transformers_config: utils.configs.ModelConfig, *args, **kwargs)

   Bases: :py:obj:`base.BaseWatermark`


   Top-level class for DIP algorithm.


   .. py:attribute:: config


   .. py:attribute:: utils


   .. py:attribute:: logits_processor


   .. py:method:: generate_watermarked_text(prompt: str, *args, **kwargs) -> str

      Generate watermarked text.



   .. py:method:: generate(encoded_prompts: list, *args, **kwargs) -> str

      Generate watermarked text. Takes a list of encoded prompts as input, like transformers model.generate.



   .. py:method:: detect_watermark(text: str, return_dict: bool = True, *args, **kwargs)

      Detect watermark in the text.



